{"cells":[{"cell_type":"markdown","metadata":{"id":"XslFzHBDU0cw"},"source":["# Korean-Abstractive-Summarization: huggingface_t5-large-korean-text-summary \n","- TEAM: ChatGPT"]},{"cell_type":"markdown","metadata":{"id":"rDVI1hlgU2eI"},"source":["## 1. Install and Setting library "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222665,"status":"ok","timestamp":1680090317453,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"ilOpLUpf5K-I","outputId":"209b95d5-fa09-4ef1-9d53-e387e9e3e51b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kss\n","  Downloading kss-4.5.1.tar.gz (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting emoji==1.2.0\n","  Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from kss) (2022.10.31)\n","Collecting pecab\n","  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from kss) (3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pecab->kss) (1.22.4)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/dist-packages (from pecab->kss) (9.0.0)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.9/dist-packages (from pecab->kss) (7.2.2)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest->pecab->kss) (1.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pytest->pecab->kss) (23.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest->pecab->kss) (22.2.0)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest->pecab->kss) (2.0.0)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest->pecab->kss) (2.0.1)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest->pecab->kss) (1.1.1)\n","Building wheels for collected packages: kss, pecab\n","  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kss: filename=kss-4.5.1-py3-none-any.whl size=53220 sha256=88aa837c810649ce791f0ed649b6a4270a86a7d479729a4d98197c94f84ca27d\n","  Stored in directory: /root/.cache/pip/wheels/2f/23/d1/e9c8f5f2e8a61bb4cb8e4fdd0d0c951dab78882e3807c7f7ca\n","  Building wheel for pecab (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646666 sha256=2e063ab976620d077891efd2862f26cc70f93e5f4d5f220b8c7ff4fc40a94224\n","  Stored in directory: /root/.cache/pip/wheels/5c/91/bf/14eed6eafd0a83f76eab5cf8eb50ddc0b037f059eec2bd2e4a\n","Successfully built kss pecab\n","Installing collected packages: emoji, pecab, kss\n","Successfully installed emoji-1.2.0 kss-4.5.1 pecab-1.0.8\n"]}],"source":["# line breaking library\n","!pip install kss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7677,"status":"ok","timestamp":1680090325117,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"luX7EfZ_yeJX","outputId":"5fc25c03-2ef4-42a1-f6f1-4c1dc3305cd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting unidecode\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.6\n"]}],"source":["# preprocessing library\n","!pip install emoji\n","!pip install unidecode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11363,"status":"ok","timestamp":1680090336478,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"aHbEQaqvUuI3","outputId":"f794f518-4f63-41e4-a66a-c17a3926d868"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n"]}],"source":["# huggingface transformers library\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13347,"status":"ok","timestamp":1680090349822,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"1IxhIL5tZXMH","outputId":"8f8ed17d-5c05-40dc-e3a1-7247b07ddb10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["# dataset library\n","!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5748,"status":"ok","timestamp":1680090355565,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"nekyAI-MZiEK","outputId":"25f7aabd-5a7d-4496-d00a-32b1f01e8fce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.1.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=5098e5c7b913b395f1e9b20807981e94456cbffb2a5cb5ca322e68d69b1f6f2d\n","  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}],"source":["# metrics library\n","!pip install rouge_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5830,"status":"ok","timestamp":1680090361392,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"bCTyecj9U4NC","outputId":"e48cd69c-e3f1-478e-9a0e-a553dc76c369"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping sentencepiece as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}],"source":["!pip uninstall sentencepiece\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I19BWFjGU4F4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"SqrNUtjyU4oP"},"source":["## 2. Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25628,"status":"ok","timestamp":1680090395346,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"7NHa_E6RU5s3","outputId":"b83120f2-522f-4357-f5f4-6002c3589826"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 드라이브와 연동합니다. 권한 허용이 필요합니다.\n","from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUcNvTTfU8yZ"},"outputs":[],"source":["# 테스트 데이터를 HuggingFace Dataset으로 불러옵니다.\n","import pandas as pd\n","data_path = '/content/drive/MyDrive/공모전/GPT_Competition/data/train.csv'\n","train = pd.read_csv(data_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680090402703,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"ol8uiXSFU9-k","outputId":"e8be0a1b-30af-4a39-c325-aeceb2e32597"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              id  \\\n","0      REPORT-news_r-00007-00001   \n","1      REPORT-news_r-00018-00001   \n","2      REPORT-news_r-00020-00002   \n","3      REPORT-news_r-00024-00001   \n","4      REPORT-news_r-00029-00001   \n","...                          ...   \n","40395  REPORT-speech-16815-00004   \n","40396  REPORT-speech-16815-00005   \n","40397  REPORT-speech-16817-00002   \n","40398  REPORT-speech-16819-00001   \n","40399  REPORT-speech-16820-00001   \n","\n","                                                    text  \\\n","0      보수진영 사분오열 속 ‘국민통합연대’ 띄운 비박계 크리스마스를 앞둔 지난 23일 오...   \n","1      가난 속에서 맨손으로 혼자 창업해 30대 중반에 코스닥 상장까지 일궈낸 이가 있다....   \n","2         SK텔레콤은 ‘T끼리 온가족 할인’ 요금제로, 가족 구성원의 가입 합산 기간이...   \n","3      “박스 테이프는 어디 갔죠?” 1일 오전 서울 중구의 한 대형마트.\\n  장을 본 ...   \n","4      현대차그룹 고급 브랜드 제네시스의 첫 스포츠유틸리티차량(SUV), GV80이 드디어...   \n","...                                                  ...   \n","40395  이것들이 잘할 수 있도록 저희들이 워크숍을 예정하는데 한국고용정보원하고 한국청소년정...   \n","40396  그래서 10~12월간 제조업체 등을 대상으로 해서 관련된 자율진단을 하고 필요하면 ...   \n","40397  마지막으로 10월 4일에는 슈타인 마이어 독일 연방정부 대통령을 예방합니다. 이 자...   \n","40398  안녕하십니까? 국민권익위원회 대변인 허재우입니다. 9월 넷째 주 정례브리핑입니다. ...   \n","40399  안녕하십니까? 과기정통부 대변인실 김세준입니다. 9월 27일 월요일 정례브리핑을 시...   \n","\n","                                                 summary  \n","0      국민통합연대가 연 창립대회에 자유한국당 홍 전 대표 등 의원 20여 명을 포함한 5...  \n","1      아이엘사이언스 대표 송 씨는 발광다이오드 조명용 실리콘 렌즈를 세계 최초로 개발하여...  \n","2      SK텔레콤은 T끼리 온가족 할인으로 요금을 깎아주거나 30년 이상 가입자를 위해 호...  \n","3      대형마트 3사가 장바구니 사용을 독려하고 플라스틱 폐기물을 줄이기 위해 포장용 테이...  \n","4      현대차그룹은 제네시스를 이끌 GV80의 내·외관 사진을 공개하며 이달 중 출시한다고...  \n","...                                                  ...  \n","40395  전국기능경기대회는 심각한 코로나 상황으로 인해 방역에 특히 신경을 써서 추진하고자 한다.  \n","40396  이륜차 사고예방 시범사업은 이동시간 논란이 많은 배달업 종사원들에 대해 안전 배달시...  \n","40397  강원도 철원군에서 2021년 통일로가요 결선 경연을 개최하며 결선에 진출한 12개 ...  \n","40398  국민권익위는 경기도 소재 21개 중·고등학교를 표본으로 실태조사를 한 결과 저소득층...  \n","40399  국립중앙과학관은 국민이 직접 만든 영상 콘텐츠, 국민들과 과학관이 함께 만드는 영상...  \n","\n","[40400 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-bad0d07b-cb3f-4174-8aa3-d3b02e996545\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>REPORT-news_r-00007-00001</td>\n","      <td>보수진영 사분오열 속 ‘국민통합연대’ 띄운 비박계 크리스마스를 앞둔 지난 23일 오...</td>\n","      <td>국민통합연대가 연 창립대회에 자유한국당 홍 전 대표 등 의원 20여 명을 포함한 5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>REPORT-news_r-00018-00001</td>\n","      <td>가난 속에서 맨손으로 혼자 창업해 30대 중반에 코스닥 상장까지 일궈낸 이가 있다....</td>\n","      <td>아이엘사이언스 대표 송 씨는 발광다이오드 조명용 실리콘 렌즈를 세계 최초로 개발하여...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>REPORT-news_r-00020-00002</td>\n","      <td>SK텔레콤은 ‘T끼리 온가족 할인’ 요금제로, 가족 구성원의 가입 합산 기간이...</td>\n","      <td>SK텔레콤은 T끼리 온가족 할인으로 요금을 깎아주거나 30년 이상 가입자를 위해 호...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>REPORT-news_r-00024-00001</td>\n","      <td>“박스 테이프는 어디 갔죠?” 1일 오전 서울 중구의 한 대형마트.\\n  장을 본 ...</td>\n","      <td>대형마트 3사가 장바구니 사용을 독려하고 플라스틱 폐기물을 줄이기 위해 포장용 테이...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>REPORT-news_r-00029-00001</td>\n","      <td>현대차그룹 고급 브랜드 제네시스의 첫 스포츠유틸리티차량(SUV), GV80이 드디어...</td>\n","      <td>현대차그룹은 제네시스를 이끌 GV80의 내·외관 사진을 공개하며 이달 중 출시한다고...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>40395</th>\n","      <td>REPORT-speech-16815-00004</td>\n","      <td>이것들이 잘할 수 있도록 저희들이 워크숍을 예정하는데 한국고용정보원하고 한국청소년정...</td>\n","      <td>전국기능경기대회는 심각한 코로나 상황으로 인해 방역에 특히 신경을 써서 추진하고자 한다.</td>\n","    </tr>\n","    <tr>\n","      <th>40396</th>\n","      <td>REPORT-speech-16815-00005</td>\n","      <td>그래서 10~12월간 제조업체 등을 대상으로 해서 관련된 자율진단을 하고 필요하면 ...</td>\n","      <td>이륜차 사고예방 시범사업은 이동시간 논란이 많은 배달업 종사원들에 대해 안전 배달시...</td>\n","    </tr>\n","    <tr>\n","      <th>40397</th>\n","      <td>REPORT-speech-16817-00002</td>\n","      <td>마지막으로 10월 4일에는 슈타인 마이어 독일 연방정부 대통령을 예방합니다. 이 자...</td>\n","      <td>강원도 철원군에서 2021년 통일로가요 결선 경연을 개최하며 결선에 진출한 12개 ...</td>\n","    </tr>\n","    <tr>\n","      <th>40398</th>\n","      <td>REPORT-speech-16819-00001</td>\n","      <td>안녕하십니까? 국민권익위원회 대변인 허재우입니다. 9월 넷째 주 정례브리핑입니다. ...</td>\n","      <td>국민권익위는 경기도 소재 21개 중·고등학교를 표본으로 실태조사를 한 결과 저소득층...</td>\n","    </tr>\n","    <tr>\n","      <th>40399</th>\n","      <td>REPORT-speech-16820-00001</td>\n","      <td>안녕하십니까? 과기정통부 대변인실 김세준입니다. 9월 27일 월요일 정례브리핑을 시...</td>\n","      <td>국립중앙과학관은 국민이 직접 만든 영상 콘텐츠, 국민들과 과학관이 함께 만드는 영상...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>40400 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bad0d07b-cb3f-4174-8aa3-d3b02e996545')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bad0d07b-cb3f-4174-8aa3-d3b02e996545 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bad0d07b-cb3f-4174-8aa3-d3b02e996545');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680090402703,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"30ynXkNEVWqe","outputId":"d97d5ae9-595c-4063-fac8-672db4e8e913"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'보수진영 사분오열 속 ‘국민통합연대’ 띄운 비박계 크리스마스를 앞둔 지난 23일 오전 서울 프레스센터 국제회의실.\\n  보수분열 극복을 내건 ‘국민통합연대’가 창립대회를 열었다.\\n  햇살 없이 착 가라앉은 날씨에 동지 바람이 매서웠지만 행사장 안은 달아올랐다.\\n  문재인 정권을 향한 맹폭격이 이어졌고 ‘무능, 기만의 오만방자한 정권에 사망을 선고한다’는 창립선언문이 나왔다.\\n  홍준표 전 자유한국당 대표 등 전현직 의원 20여명을 포함해 500여명이 자리를 빼곡하게 메웠다.\\n  총선이 불과 석달 남짓이다.\\n  야권 인사들이 정권을 두들겨 패는 거야 이상한 일이 아니다.\\n  눈 여겨 볼 대목은 모인 사람이 대부분 친이·비박계(친이명박·비박근혜) 인사들이란 점이다.\\n  박관용 전 국회의장, 이문열 작가와 함께 보수쪽 명망가 여럿이 이름을 올리고 더러 참석했다.\\n  전광훈 목사는 축사를 했다.\\n  그래도 이명박 정권서 요직을 맡았던 사람들이 주축이다.\\n  이재오 중앙집행위원장과 홍준표 전 대표가 한가운데 있다.\\n  두 사람은 ‘친박 그룹’에 둘러싸인 황교안 대표와 한국당에 불편한 기색을 감추지 않는 중이다.\\n  홍 전 대표는 이튿날 “무기력한 야당만 믿고 따르기엔 너무 답답하고 앞날이 보이지 않아 창립한 게 국민통합연대”란 글을 올렸다.\\n  31일엔 “한국당 지도부는 총사퇴하고 비상대책위를 꾸려야 한다”고 황 대표 사퇴를 요구했다.\\n  이재오 위원장은 지난 10월3일 광화문의 조국 규탄집회장에서 “자유한국당은 집회에서 빠지라”고 외쳤다.\\n  가뜩이나 뿔뿔이 흩어진 각자도생의 보수세력이다.\\n  한국당과 우리공화당에다 새로운 보수당, 이언주 신당, 이정현 신당이 나올 판이다.\\n  게다가 개정선거법의 준연동형 비례대표제는 군소정당에 유리한 분열요인이다.\\n  중앙선관위에 등록된 정당이 34개인데 창당준비위원회를 설립한 예비정당만 16개에 달한다.\\n  야권 빅텐트를 외칠만한 상황이긴 하다.\\n  그런데 통합을 내건 이재오 위원장은 “어느 한 정당이나 단체 중 힘 있는 정당, 단체를 중심으로 뭘 하자는 식의 통합은 어렵다”고 주장했다.\\n  황교안 대표와 한국당 중심의 보수 통합론을 가로막고 나선 셈이다.\\n  그렇다고 ‘힘 있는’ 한국당이 ‘힘 없는’ 국민통합연대의 주문에 따를 리는 없다.\\n  결국 친이계가 떨어져 나가는 ‘보수 4분열’이란 해석이 나왔다.\\n  정말 그럴까.\\n  국민통합연대는 조만간 친이 비박 신당으로 탈바꿈할 것인가.\\n '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["train['text'].loc[0]"]},{"cell_type":"markdown","source":["### 2-1. Line breaking\n","- 일부 데이터에서 줄바꿈되지 않은 문장이 존재하여 변환"],"metadata":{"id":"X-imPPU8jCbJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq3aSikm5E0Q"},"outputs":[],"source":["from kss import split_sentences\n","\n","idx= []; org_idx = []\n","for i in range(len(train)):\n","    if '\\n' not in train['text'][i]:\n","        idx.append(i)\n","    else:\n","        org_idx.append(i)\n","\n","refine_df = train.iloc[idx, :];org_df = train.iloc[org_idx, :]\n","for i in idx:\n","    refine_df.loc[i,'text'] = '\\n'.join(split_sentences(refine_df.loc[i,'text'])) \n","\n","final_df = pd.concat([org_df,refine_df], axis = 0)\n","final_df = final_df.sort_index(ascending=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iq9JuGJ97bgj"},"outputs":[],"source":["final_df.to_csv('/content/drive/MyDrive/공모전/GPT_Competition/data/retain_train.csv', index=False)"]},{"cell_type":"code","source":["final_df = pd.read_csv('/content/drive/MyDrive/공모전/GPT_Competition/data/retain_train.csv')[['id', 'text', 'summary']]"],"metadata":{"id":"k-pfqVfkGRi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mft4xHTlGZJa","executionInfo":{"status":"ok","timestamp":1680096499287,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"0e245160-4024-45f6-80c6-c5a3883f2d01"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                          id  \\\n","0  REPORT-news_r-00007-00001   \n","1  REPORT-news_r-00018-00001   \n","2  REPORT-news_r-00020-00002   \n","3  REPORT-news_r-00024-00001   \n","4  REPORT-news_r-00029-00001   \n","\n","                                                text  \\\n","0  보수진영 사분오열 속 ‘국민통합연대’ 띄운 비박계 크리스마스를 앞둔 지난 23일 오...   \n","1  가난 속에서 맨손으로 혼자 창업해 30대 중반에 코스닥 상장까지 일궈낸 이가 있다....   \n","2     SK텔레콤은 ‘T끼리 온가족 할인’ 요금제로, 가족 구성원의 가입 합산 기간이...   \n","3  “박스 테이프는 어디 갔죠?” 1일 오전 서울 중구의 한 대형마트.\\n  장을 본 ...   \n","4  현대차그룹 고급 브랜드 제네시스의 첫 스포츠유틸리티차량(SUV), GV80이 드디어...   \n","\n","                                             summary  \n","0  국민통합연대가 연 창립대회에 자유한국당 홍 전 대표 등 의원 20여 명을 포함한 5...  \n","1  아이엘사이언스 대표 송 씨는 발광다이오드 조명용 실리콘 렌즈를 세계 최초로 개발하여...  \n","2  SK텔레콤은 T끼리 온가족 할인으로 요금을 깎아주거나 30년 이상 가입자를 위해 호...  \n","3  대형마트 3사가 장바구니 사용을 독려하고 플라스틱 폐기물을 줄이기 위해 포장용 테이...  \n","4  현대차그룹은 제네시스를 이끌 GV80의 내·외관 사진을 공개하며 이달 중 출시한다고...  "],"text/html":["\n","  <div id=\"df-9386808f-210b-447d-bc3a-5ef4a334f5ad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>REPORT-news_r-00007-00001</td>\n","      <td>보수진영 사분오열 속 ‘국민통합연대’ 띄운 비박계 크리스마스를 앞둔 지난 23일 오...</td>\n","      <td>국민통합연대가 연 창립대회에 자유한국당 홍 전 대표 등 의원 20여 명을 포함한 5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>REPORT-news_r-00018-00001</td>\n","      <td>가난 속에서 맨손으로 혼자 창업해 30대 중반에 코스닥 상장까지 일궈낸 이가 있다....</td>\n","      <td>아이엘사이언스 대표 송 씨는 발광다이오드 조명용 실리콘 렌즈를 세계 최초로 개발하여...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>REPORT-news_r-00020-00002</td>\n","      <td>SK텔레콤은 ‘T끼리 온가족 할인’ 요금제로, 가족 구성원의 가입 합산 기간이...</td>\n","      <td>SK텔레콤은 T끼리 온가족 할인으로 요금을 깎아주거나 30년 이상 가입자를 위해 호...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>REPORT-news_r-00024-00001</td>\n","      <td>“박스 테이프는 어디 갔죠?” 1일 오전 서울 중구의 한 대형마트.\\n  장을 본 ...</td>\n","      <td>대형마트 3사가 장바구니 사용을 독려하고 플라스틱 폐기물을 줄이기 위해 포장용 테이...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>REPORT-news_r-00029-00001</td>\n","      <td>현대차그룹 고급 브랜드 제네시스의 첫 스포츠유틸리티차량(SUV), GV80이 드디어...</td>\n","      <td>현대차그룹은 제네시스를 이끌 GV80의 내·외관 사진을 공개하며 이달 중 출시한다고...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9386808f-210b-447d-bc3a-5ef4a334f5ad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9386808f-210b-447d-bc3a-5ef4a334f5ad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9386808f-210b-447d-bc3a-5ef4a334f5ad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["# document length\n","train_text = final_df['text'].apply(len)"],"metadata":{"id":"d4oy5AQOZrse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_text.describe() # 1500"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAt7NPfDZ07X","executionInfo":{"status":"ok","timestamp":1680096499288,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"406c3fce-bba1-4d59-8621-ee5c1c85e684"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    40400.000000\n","mean       921.470074\n","std        221.744665\n","min        687.000000\n","25%        738.000000\n","50%        805.000000\n","75%       1208.000000\n","max       1499.000000\n","Name: text, dtype: float64"]},"metadata":{},"execution_count":111}]},{"cell_type":"code","source":["# summary length\n","train_summ = final_df['summary'].apply(len)"],"metadata":{"id":"5kqKIedoZ3w1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_summ.describe() # 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUHCe0qYZ-Po","executionInfo":{"status":"ok","timestamp":1680096499288,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"59043349-d7a0-4d55-94f0-114ea9903603"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    40400.000000\n","mean        80.493094\n","std         15.862411\n","min         16.000000\n","25%         70.000000\n","50%         84.000000\n","75%         94.000000\n","max        100.000000\n","Name: summary, dtype: float64"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["### 2-2. Preprocessing"],"metadata":{"id":"sQjt1fArjSYw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vx38pt-cyksJ"},"outputs":[],"source":["import re\n","import emoji\n","from unidecode import unidecode\n","import numpy as np\n","\n","#remove html tags\n","def removeHTML(x):\n","    html=re.compile(r'<.*?>')\n","    return html.sub(r'',x)\n","    \n","\n","def dataPreprocessing(x):\n","    # x = x.lower() # 대소문자 분류가 필요할지도 몰라서 주석처리\n","    x = removeHTML(x)\n","    x = emoji.demojize(x, delimiters=(\" \", \" \"))\n","    x = re.sub(r'[^ 가-힣A-Za-z0-9\\'.,?!/\\n\\r()%\\[\\]\\-+~$&\"]·', '', x)\n","    x = re.sub(r'[ ]+', ' ', x) # 공백 두칸 이상 지우기\n","    x = x.strip()\n","    return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7jYQOUoykle"},"outputs":[],"source":["final_df[\"text\"]=final_df[\"text\"].apply(lambda x: dataPreprocessing(x))"]},{"cell_type":"code","source":["final_df.head()"],"metadata":{"id":"EQias73X0zls","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1680096711958,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"f4c81be3-74ae-450b-c677-3bd54c4ef747"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                          id  \\\n","0  REPORT-news_r-00007-00001   \n","1  REPORT-news_r-00018-00001   \n","2  REPORT-news_r-00020-00002   \n","3  REPORT-news_r-00024-00001   \n","4  REPORT-news_r-00029-00001   \n","\n","                                                text  \\\n","0  보수진영 사분오열 속 ‘국민통합연대’ 띄운 비박계 크리스마스를 앞둔 지난 23일 오...   \n","1  가난 속에서 맨손으로 혼자 창업해 30대 중반에 코스닥 상장까지 일궈낸 이가 있다....   \n","2  SK텔레콤은 ‘T끼리 온가족 할인’ 요금제로, 가족 구성원의 가입 합산 기간이 20...   \n","3  “박스 테이프는 어디 갔죠?” 1일 오전 서울 중구의 한 대형마트.\\n 장을 본 사...   \n","4  현대차그룹 고급 브랜드 제네시스의 첫 스포츠유틸리티차량(SUV), GV80이 드디어...   \n","\n","                                             summary  \n","0  국민통합연대가 연 창립대회에 자유한국당 홍 전 대표 등 의원 20여 명을 포함한 5...  \n","1  아이엘사이언스 대표 송 씨는 발광다이오드 조명용 실리콘 렌즈를 세계 최초로 개발하여...  \n","2  SK텔레콤은 T끼리 온가족 할인으로 요금을 깎아주거나 30년 이상 가입자를 위해 호...  \n","3  대형마트 3사가 장바구니 사용을 독려하고 플라스틱 폐기물을 줄이기 위해 포장용 테이...  \n","4  현대차그룹은 제네시스를 이끌 GV80의 내·외관 사진을 공개하며 이달 중 출시한다고...  "],"text/html":["\n","  <div id=\"df-745ced9f-e69b-454e-a5ad-c76876bb12df\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>REPORT-news_r-00007-00001</td>\n","      <td>보수진영 사분오열 속 ‘국민통합연대’ 띄운 비박계 크리스마스를 앞둔 지난 23일 오...</td>\n","      <td>국민통합연대가 연 창립대회에 자유한국당 홍 전 대표 등 의원 20여 명을 포함한 5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>REPORT-news_r-00018-00001</td>\n","      <td>가난 속에서 맨손으로 혼자 창업해 30대 중반에 코스닥 상장까지 일궈낸 이가 있다....</td>\n","      <td>아이엘사이언스 대표 송 씨는 발광다이오드 조명용 실리콘 렌즈를 세계 최초로 개발하여...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>REPORT-news_r-00020-00002</td>\n","      <td>SK텔레콤은 ‘T끼리 온가족 할인’ 요금제로, 가족 구성원의 가입 합산 기간이 20...</td>\n","      <td>SK텔레콤은 T끼리 온가족 할인으로 요금을 깎아주거나 30년 이상 가입자를 위해 호...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>REPORT-news_r-00024-00001</td>\n","      <td>“박스 테이프는 어디 갔죠?” 1일 오전 서울 중구의 한 대형마트.\\n 장을 본 사...</td>\n","      <td>대형마트 3사가 장바구니 사용을 독려하고 플라스틱 폐기물을 줄이기 위해 포장용 테이...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>REPORT-news_r-00029-00001</td>\n","      <td>현대차그룹 고급 브랜드 제네시스의 첫 스포츠유틸리티차량(SUV), GV80이 드디어...</td>\n","      <td>현대차그룹은 제네시스를 이끌 GV80의 내·외관 사진을 공개하며 이달 중 출시한다고...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-745ced9f-e69b-454e-a5ad-c76876bb12df')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-745ced9f-e69b-454e-a5ad-c76876bb12df button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-745ced9f-e69b-454e-a5ad-c76876bb12df');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":["final_df.loc[100]['text']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"G6VaEjz3UnNo","executionInfo":{"status":"ok","timestamp":1680096711958,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"79614e40-faf9-4130-dbe1-a1858d8e95aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'유튜브가 정치권에 미치는 영향이 날로 커지고 있다.\\n 각종 정치 이슈가 확대·재생산되며 각 당과 의원들도 민감하게 반응하고 있다.\\n 6일로 100일 앞으로 다가온 4·15 총선에서 ‘유튜브 활용법’이 판도를 가를 것이란 분석까지 나온다.\\n 이번 총선은 여러 면에서 기존 선거와 다른 양상을 보일 것으로 예상된다.\\n 우선 진보와 보수 모두 극단적 쏠림 현상이 뚜렷하다.\\n 자유한국당은 황교안 대표가 ‘탄핵 국면’을 적극 활용하며 보수색이 더 짙어졌다.\\n 더불어민주당 역시 이른바 ‘문빠(문재인 대통령 열혈 지지자)’ 등 지지 세력을 규합하는데 총력을 쏟고 있다.\\n 중원(中原)을 겨냥해 표심을 확장하는 통상의 선거 전략과는 다른 모습이다.\\n 더불어민주당의 한 핵심 관계자는 \"각 당이 우선은 ‘집토끼’를 확실히 붙잡아 둬야 한다는 압박이 있어 당분간은 여야 모두 중도층을 공략하는 전략보단 지지 세력을 규합하기 위한 움직임이 계속될 것”이라고 말했다.\\n 이런 상황에서 집토끼를 단속하기 위한 수단으로 유튜브의 중요성이 더 부각되고 있다.\\n 현재 유튜브 정치 지형은 보수 진영이 우위를 선점한 가운데 진보 진영이 세를 확장하려는 상황으로 요약된다.\\n 유튜브 장악한 보수 채널 유튜브 내 정치 생태계에선 보수 채널이 강세다.\\n 정치 관련 유튜브 채널 중 구독자 수 1위인 ‘신의 한수’가 대표적이다.\\n 애국보수를 표방하는 이 채널은 구독자 수가 116만명에 달한다.\\n 지난해 12월부터 이어지는 한국당의 집회·농성장에 참가자들을 끌어 모으는 구심점 역할을 했다.\\n 이외에도 진성호방송(구독자 76만명)·딴지방송국(71만명)·정규재TV(63만명)·고성국TV(51만명)·TV홍카콜라(36만명) 등이 있는데, 열혈팬이 많은 편이다.\\n 유튜브에선 통상 구독자 수 대비 조회수 기준으로 해당 채널의 활동성과 파급력을 평가한다.\\n 보수 성향의 주요 유튜브 채널은 구독자 수 대비 조회수가 평균 50% 수준으로, 구독자 중 절반 이상은 채널에 올라오는 영상을 빠짐 없이 본다는 얘기다.\\n 또 보수 유튜브 채널에선 트위터·페이스북 등 소셜네트워크서비스(SNS) 흐름에 상대적으로 소외됐던 중·장년층의 활동이 유독 활발하단 특징도 있다.\\n 구독자 76만명의 진성호방송을 운영하는 진성호 전 새누리당(한국당 전신) 의원은 “유튜브의 가장 큰 장점은 빠른 피드백과 그에 따른 양방 소통”이라며 “유튜브를 기성 언론과 굳이 비교하자면 일반 기사가 아닌 제도권 언론의 사설·평론과 비슷한 형식인데 그 누구의 간섭도 받지 않고 내 소신과 신념에 따라 가치관을 담은 영상을 내보낼 수 있다”고 말했다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["# document length\n","train_text = final_df['text'].apply(len)\n","train_text.describe() # 100"],"metadata":{"id":"n-afdaT80msp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680096711959,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"1382afe4-715c-476a-dede-6da36d017ee9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    40400.000000\n","mean       912.081089\n","std        213.444188\n","min        579.000000\n","25%        735.000000\n","50%        802.000000\n","75%       1183.000000\n","max       1491.000000\n","Name: text, dtype: float64"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["# document length\n","train_summ = final_df['summary'].apply(len)\n","train_summ.describe() # 100"],"metadata":{"id":"obvImWZv0u6x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680096711959,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"e95b65ed-42ae-4b6a-bba0-27f0fbb6d120"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    40400.000000\n","mean        80.493094\n","std         15.862411\n","min         16.000000\n","25%         70.000000\n","50%         84.000000\n","75%         94.000000\n","max        100.000000\n","Name: summary, dtype: float64"]},"metadata":{},"execution_count":119}]},{"cell_type":"markdown","source":["### 2-3. Split train and test dataset "],"metadata":{"id":"blS9zLtFjfFL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHjeEomHdzFY"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# train과 test 데이터로 분리\n","train_df, test_df = train_test_split(final_df, test_size=0.2, random_state=24)"]},{"cell_type":"markdown","metadata":{"id":"eL6JTj74WdUz"},"source":["## 3. Load model and tokenizer\n","- Train Model: T5\n","    - https://huggingface.co/noahkim/KoT5_news_summarization\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGoZdANNXl3h"},"outputs":[],"source":["# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer"]},{"cell_type":"markdown","source":["- fine tuning을 위한 tokenizer 및 model 로드"],"metadata":{"id":"dhtp49sikTl7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZER-nfgVYhf"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"noahkim/KoT5_news_summarization\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/공모전/GPT_Competition/t5_large_230328/results_t5_large_230328/checkpoint-100\") # 지난 최적 모델부터 다시 학습"]},{"cell_type":"markdown","source":["- device 설정 (GPU 사용을 권장)"],"metadata":{"id":"ONSeIs11kMYE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymIxZu1gXs2g"},"outputs":[],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","source":["- 입력과 출력 길이 설정"],"metadata":{"id":"4tOSddRuka3X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8UiH63XXnPF"},"outputs":[],"source":["max_input_length = 1024\n","max_output_length = 100"]},{"cell_type":"markdown","source":["- 입력 및 출력 토큰화 함수 정의"],"metadata":{"id":"ExBneKzakdQM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ZqQnZDGXnHE"},"outputs":[],"source":["def tokenize(batch):\n","    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=max_input_length)\n","\n","def summarize(batch):\n","    return tokenizer(batch['summary'], padding='max_length', truncation=True, max_length=max_output_length)"]},{"cell_type":"markdown","source":["- 학습 데이터셋 및 데이터로더 생성"],"metadata":{"id":"NBDYfqCckfNf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxAtkFkuXnBU"},"outputs":[],"source":["train_dataset = []\n","for i in range(len(train_df)):\n","    data = {\n","        'id': train_df.iloc[i]['id'],\n","        'input_ids': None,\n","        'attention_mask': None,\n","        'decoder_input_ids': None,\n","        'decoder_attention_mask': None,\n","        'labels': None\n","    }\n","\n","    # 입력과 출력을 토큰화\n","    input = tokenizer.encode_plus(train_df.iloc[i]['text'], max_length=max_input_length, padding='max_length', truncation=True, return_tensors='pt')\n","    output = tokenizer.encode_plus(train_df.iloc[i]['summary'], max_length=max_output_length, padding='max_length', truncation=True, return_tensors='pt')\n","\n","    # 토큰 ID와 어텐션 마스크를 입력 데이터로 저장\n","    data['input_ids'] = input['input_ids'][0]\n","    data['attention_mask'] = input['attention_mask'][0]\n","\n","    # 토큰 ID와 어텐션 마스크를 출력 데이터로 저장\n","    data['decoder_input_ids'] = output['input_ids'][0]\n","    data['decoder_attention_mask'] = output['attention_mask'][0]\n","\n","    # 라벨 데이터로 저장\n","    data['labels'] = output['input_ids'][0].clone().detach()\n","\n","    # 라벨에서 PAD 토큰의 위치를 마스크하여 불필요한 손실 계산 방지\n","    data['labels'][data['labels'] == tokenizer.pad_token_id] = -100\n","\n","    train_dataset.append(data)"]},{"cell_type":"code","source":["test_df.iloc[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vrXkQnnde_yQ","executionInfo":{"status":"ok","timestamp":1680096828572,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"be5a8f28-f5a5-4506-d3f2-5281926de224"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                                 REPORT-minute-00015-02490\n","text       노웅래 위원] \"이상입니다.\"\\n위원장 진영] \"수고하셨습니다. 다음은 강기윤 위원...\n","summary    강 위원은 안전처가 생긴다면 소방공무원은 어떻게 해야 할까 하는 의문이 들어야 하고...\n","Name: 11459, dtype: object"]},"metadata":{},"execution_count":129}]},{"cell_type":"markdown","source":["- 테스트 데이터셋 및 데이터로더 생성"],"metadata":{"id":"gitJNN3nklTD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZhmdL5Ud55e"},"outputs":[],"source":["test_dataset = []\n","for i in range(len(test_df)):\n","    data = {\n","        'id': test_df.iloc[i]['id'],\n","        'input_ids': None,\n","        'attention_mask': None,\n","        'decoder_input_ids': None,\n","        'decoder_attention_mask': None,\n","        'labels': None\n","    }\n","\n","    # 입력과 출력을 토큰화\n","    input = tokenizer.encode_plus(test_df.iloc[i]['text'], max_length=max_input_length, padding='max_length', truncation=True, return_tensors='pt')\n","    output = tokenizer.encode_plus(test_df.iloc[i]['summary'], max_length=max_output_length, padding='max_length', truncation=True, return_tensors='pt')\n","\n","    # 토큰 ID와 어텐션 마스크를 입력 데이터로 저장\n","    data['input_ids'] = input['input_ids'][0]\n","    data['attention_mask'] = input['attention_mask'][0]\n","\n","    # 토큰 ID와 어텐션 마스크를 출력 데이터로 저장\n","    data['decoder_input_ids'] = output['input_ids'][0]\n","    data['decoder_attention_mask'] = output['attention_mask'][0]\n","\n","    # 라벨 데이터로 저장\n","    data['labels'] = output['input_ids'][0].clone().detach()\n","\n","    # 라벨에서 PAD 토큰의 위치를 마스크하여 불필요한 손실 계산 방지\n","    data['labels'][data['labels'] == tokenizer.pad_token_id] = -100\n","\n","    test_dataset.append(data)"]},{"cell_type":"markdown","source":["- 데이터 수집기 및 학습/테스트 데이터셋 로더 생성"],"metadata":{"id":"P6VkALcKkn0v"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXCabD57YmN7"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,model=model)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=data_collator)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=data_collator)"]},{"cell_type":"markdown","source":["## 4. Custom metrics\n","- ROUGE-1,2,L (F1)"],"metadata":{"id":"kXg1N4Isk_Fi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IvBx4DTXm53"},"outputs":[],"source":["# 학습용 평가\n","from datasets import load_metric\n","rouge_metric = load_metric(\"rouge\")\n","\n","def compute_metrics(pred):\n","    predictions = pred.predictions\n","    labels = pred.label_ids\n","\n","    # Decode the prediction and label ids to texts\n","    # Replace -100 in the labels as we can't decode them.\n","    predictions = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]\n","    labels = [tokenizer.decode(np.where(np.array(label) == -100, 0, label).tolist(), skip_special_tokens=True) for label in labels]\n","\n","    # Calculate ROUGE scores\n","    rouge_output = rouge_metric.compute(predictions=predictions, references=labels, use_stemmer=True)\n","    \n","    # Extract precision, recall, fmeasure for each ROUGE score\n","    rouge1 = rouge_output[\"rouge1\"].mid\n","    rouge2 = rouge_output[\"rouge2\"].mid\n","    rougeL = rouge_output[\"rougeL\"].mid\n","\n","    return {\n","        \"rouge1_fmeasure\": rouge1.fmeasure,\n","        \"rouge2_fmeasure\": rouge2.fmeasure,\n","        \"rougeL_fmeasure\": rougeL.fmeasure,\n","    }"]},{"cell_type":"markdown","source":["- GPU 캐시 초기화"],"metadata":{"id":"NPXj36y5kwxB"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680096855227,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"h_bi7Q0YaKAl","outputId":"d0b66a32-9533-4fb0-ad2e-fe797b5723a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":133}],"source":["import torch \n","import gc\n","\n","torch.cuda.empty_cache() \n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680096855975,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"},"user_tz":-540},"id":"GkUCcM57eLuP","outputId":"2611ac9e-9057-4d85-cd14-e5f1ea48e4bf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":134}],"source":["import torch \n","import gc\n","\n","torch.cuda.empty_cache() \n","gc.collect()"]},{"cell_type":"markdown","source":["## 5. Train model"],"metadata":{"id":"dd0rtskClOFm"}},{"cell_type":"code","source":["from transformers import EarlyStoppingCallback\n","\n","# EarlyStoppingCallback 초기화\n","early_stopping = EarlyStoppingCallback(early_stopping_patience=100, early_stopping_threshold=0.01)"],"metadata":{"id":"ODaPuid-SjOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","from transformers import AdamW\n","\n","# 파인튜닝을 위한 argument 설정\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir='/content/drive/MyDrive/공모전/GPT_Competition/t5_final_model/results_t5_final_230329',\n","    evaluation_strategy = \"steps\",\n","    eval_steps = 100, # Number of update steps between two evaluations.\n","    save_steps= 100, # after # steps model is saved \n","    warmup_steps= 200,# number of warmup steps for learning rate scheduler\n","    num_train_epochs = 5,\n","    learning_rate = 2e-5,\n","    per_device_train_batch_size = 2,\n","    per_device_eval_batch_size = 2,\n","    weight_decay = 0.01,\n","    push_to_hub=False,\n","    logging_dir='/content/drive/MyDrive/공모전/GPT_Competition/t5_final_model/logs_t5_final_230329',\n","    logging_steps=100,\n","    overwrite_output_dir=True,\n","    predict_with_generate=True,\n","    load_best_model_at_end = True,\n","    gradient_accumulation_steps=2,\n","    seed=42\n",")\n","optimizer = AdamW(model.parameters(), lr=training_args.learning_rate, eps=1e-8)\n","\n","# trainer 객체 생성\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    callbacks=[early_stopping],\n","    optimizers=(optimizer, None)\n",")\n","\n","# 파인튜닝 시작\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":781},"id":"UYlojk1DWHGm","executionInfo":{"status":"error","timestamp":1680126153948,"user_tz":-540,"elapsed":29297979,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"fc3f607c-e835-4343-87d1-483eee6f34d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='901' max='40400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  901/40400 7:52:56 < 346:19:36, 0.03 it/s, Epoch 0.11/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1 Fmeasure</th>\n","      <th>Rouge2 Fmeasure</th>\n","      <th>Rougel Fmeasure</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.785900</td>\n","      <td>0.705539</td>\n","      <td>0.126698</td>\n","      <td>0.017760</td>\n","      <td>0.126457</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.779000</td>\n","      <td>0.704115</td>\n","      <td>0.123370</td>\n","      <td>0.017065</td>\n","      <td>0.123409</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.778200</td>\n","      <td>0.702407</td>\n","      <td>0.119287</td>\n","      <td>0.016661</td>\n","      <td>0.118929</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.776200</td>\n","      <td>0.700535</td>\n","      <td>0.118460</td>\n","      <td>0.016214</td>\n","      <td>0.118268</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.790200</td>\n","      <td>0.698328</td>\n","      <td>0.123577</td>\n","      <td>0.017110</td>\n","      <td>0.123425</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.778700</td>\n","      <td>0.701000</td>\n","      <td>0.123772</td>\n","      <td>0.017168</td>\n","      <td>0.123563</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.758500</td>\n","      <td>0.702042</td>\n","      <td>0.126056</td>\n","      <td>0.017560</td>\n","      <td>0.125614</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.759400</td>\n","      <td>0.698527</td>\n","      <td>0.124525</td>\n","      <td>0.017035</td>\n","      <td>0.124081</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='1110' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1110/4040 15:18 < 40:27, 1.21 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-136-449fd3ad26aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# 파인튜닝 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         )\n\u001b[0;32m-> 1633\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2234\u001b[0m                     )\n\u001b[1;32m   2235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     def predict(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2932\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2933\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2934\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3113\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3114\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# users from preparing a dataset with `decoder_input_ids`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mgenerated_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0;31m# 11. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m             \u001b[0meos_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m         \u001b[0meos_token_id_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0meos_token_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0moutput_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_scores\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_scores\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         output_attentions = (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0oSeqnypRyq"},"outputs":[],"source":["model.save_pretrained(\"/content/drive/MyDrive/공모전/GPT_Competition/t5_final_model/results_t5_final_230329\") # 모델 저장장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_KMRw4Cbbk9r"},"outputs":[],"source":["# trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"nyVTX4866Fr_"},"source":["## 6. Sumbit test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNPqZiEYqZKG"},"outputs":[],"source":["import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# 모델 로드\n","# model_name = 'google/pegasus-large'\n","# tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(\"noahkim/KoT5_news_summarization\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/공모전/GPT_Competition/t5_final_model/results_t5_final_230329/checkpoint-500\")\n","\n","# test 데이터프레임 읽기\n","test = pd.read_csv('/content/drive/MyDrive/공모전/GPT_Competition/data/test.csv')[['id', 'text']]"]},{"cell_type":"code","source":["test[\"text\"]=test[\"text\"].apply(lambda x: dataPreprocessing(x))"],"metadata":{"id":"MxTp8F5C95nF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from kss import split_sentences\n","\n","idx= []; org_idx = []\n","for i in range(len(test)):\n","    if '\\n' not in test['text'][i]:\n","        idx.append(i)\n","    else:\n","        org_idx.append(i)\n","\n","refine_df = test.iloc[idx, :];org_df = test.iloc[org_idx, :]\n","for i in idx:\n","    refine_df.loc[i,'text'] = '\\n'.join(split_sentences(refine_df.loc[i,'text'])) \n","\n","test = pd.concat([org_df,refine_df], axis = 0)\n","test = test.sort_index(ascending=True)"],"metadata":{"id":"opVlI2hq1pOZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680126261910,"user_tz":-540,"elapsed":6241,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"f3c4d682-8741-4731-9a24-90a43469baa7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Oh! You have mecab in your environment. Kss will take this as a backend! :D\n","\n","<ipython-input-140-c666655ad207>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  refine_df.loc[i,'text'] = '\\n'.join(split_sentences(refine_df.loc[i,'text']))\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cq41XNVgqiha"},"outputs":[],"source":["# 토큰화 함수 정의\n","def tokenize(text):\n","    input_ids = tokenizer.encode(text, truncation=True, max_length=max_input_length, padding='max_length', return_tensors='pt')\n","    return input_ids\n","\n","# test 데이터프레임에 대해 토큰화 수행\n","test_dataset = test['text'].apply(tokenize)"]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"id":"OVGAA0wo-MIg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680126264507,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"221dab8d-0119-4161-d2af-7efc09e4d0fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(50358, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50358, bias=False)\n",")"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZUpSnvwqjne"},"outputs":[],"source":["# generate 함수로 요약 결과 생성\n","generated_summaries = []\n","for input_ids in test_dataset:\n","    summary = model.generate(input_ids=input_ids.to(device), max_length=max_input_length, num_beams=4, early_stopping=True)\n","    summary = tokenizer.decode(summary[0], skip_special_tokens=True)\n","    generated_summaries.append(summary)\n","\n","# 생성된 요약 결과를 test 데이터프레임에 추가\n","test['summary'] = generated_summaries"]},{"cell_type":"markdown","source":["- 후처리 작업\n","    - [부산대 맞춤법 검사기](http://speller.cs.pusan.ac.kr/)"],"metadata":{"id":"o9Gy7bEAlm3Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7qMKGV19qxaF"},"outputs":[],"source":["import requests\n","import json\n","\n","checked = []\n","for text in test['summary']:\n","  sentences = [t+\".\" for t in text.split(\". \")]\n","  new_sentences = []\n","  for sentence in sentences:\n","    new_sentence = sentence\n","    response = requests.post('http://164.125.7.61/speller/results', data={'text1': sentence})\n","    data = response.text.split('data = [', 1)[-1].rsplit('];', 1)\n","    if len(data) > 1:\n","      data = json.loads(data[0])\n","      for err in data['errInfo']:\n","        if (int(err['correctMethod']) == 2 or  int(err['correctMethod']) == 4) and '|' not in err['candWord']:\n","          new_sentence = new_sentence.replace(err['orgStr'],err['candWord'])\n","    new_sentences.append(new_sentence)\n","  if len(new_sentences) > 0:\n","    checked.append(' '.join(new_sentences))\n","  else:\n","    checked.append(' '.join(sentences))\n"]},{"cell_type":"code","source":["test['summary'] = checked"],"metadata":{"id":"MHrJFFPWRK8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataAtferPreprocessing(x):\n","    x = re.sub(r'[.]+', ' ', x) # 결과에서 나타나는 .... 지우기\n","    x = re.sub(r'[‘’]', ' ', x) # 결과에서 나타나는 ‘지우기\n","    x = x.strip() # 문자열 양끝 공백 및 줄바꿈(\\n) 제거\n","    return x"],"metadata":{"id":"53TKtX9riy6S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test[\"summary\"]=test[\"summary\"].apply(lambda x: dataAtferPreprocessing(x))"],"metadata":{"id":"HsRG0hO6i4iV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuYHrUo1qqln"},"outputs":[],"source":["sumbit = pd.read_csv('/content/drive/MyDrive/공모전/GPT_Competition/data/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNWCRfYjqnYP"},"outputs":[],"source":["sumbit['summary'] = test['summary']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdQk8LBqqZXK"},"outputs":[],"source":["sumbit"]},{"cell_type":"markdown","source":["- 제출 파일 생성"],"metadata":{"id":"C3BaCUxPl9K8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3eOaFwD7qxeT"},"outputs":[],"source":["sumbit.to_csv('/content/drive/MyDrive/공모전/GPT_Competition/t5_large_final_submission_230329.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1CW1VzCqxcb"},"outputs":[],"source":["# 자동으로 세션을 종료하고 싶을때 사용하세요.\n","from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMkcX+wGbWRry1XG5PboacZ"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"markdown","metadata":{"id":"MdogAJjZNjt6"},"source":["# KoGPT 모델 LoRA로 학습하기\n","\n","- 학습 내용\n","  - [KoGPT](https://github.com/kakaobrain/kogpt) 파라미터를 직접 Fine-Tuning하는 대신 Low Rank 어댑터만 학습하는 LoRA 기법을 사용합니다.\n","  - HuggingFace에서 제공하는 [PEFT: Parameter-Efficient Fine-Tuning](https://github.com/huggingface/peft) 라이브러리를 활용합니다.\n","  - 학습 결과는 15MB 정도 크기의 어댑터 파라미터만 저장해도 재사용 할 수 있습니다.  \n","\n","  \n","- 환경 필요사항\n","  - 학습에는 GPU 메모리가 많이 필요하므로 colab 사용 시 유료 요금제 사용을 권장합니다.\n","  - 구글 드라이브에 `/GPT_Competition/train.csv`, `/GPT_Competition/test.csv`가 업로드 되어있어야 합니다.\n","  - 학습 결과를 구글드라이브에 저장하므로 약간의 여유공간이 필요합니다."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9BEIry22gvj","outputId":"e1e9e0cf-8023-46a7-8fbd-d06f7ecaa006","executionInfo":{"status":"ok","timestamp":1679313906757,"user_tz":-540,"elapsed":23627,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 드라이브와 연동합니다. 권한 허용이 필요합니다.\n","from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3PKbDF12aGw","outputId":"6c5ff2a1-0ad5-4f78-d67d-1b20f92fb81d","executionInfo":{"status":"ok","timestamp":1679313926445,"user_tz":-540,"elapsed":19691,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# 라이브러리를 설치합니다.\n","%pip install -q transformers datasets accelerate\n","%pip install -q peft"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"M61qfK-72nBf","executionInfo":{"status":"ok","timestamp":1679313930070,"user_tz":-540,"elapsed":3629,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os, gc\n","from tqdm.auto import tqdm\n","from datetime import datetime, timezone, timedelta\n","\n","import torch\n","from torch.utils.data import DataLoader,Dataset\n","\n","import datasets\n","import transformers\n","from transformers import AutoTokenizer, AutoModelForCausalLM \n","\n","# HuggingFace peft 라이브러리\n","from peft import get_peft_model, PeftModel, TaskType, LoraConfig"]},{"cell_type":"markdown","metadata":{"id":"wo6QTgK3RbMk"},"source":["## 데이터 셋 정의하기\n","- HuggingFace의 Dataset 클래스를 활용합니다. batch 단위로 전처리하기 편리합니다.\n","- tokenizer 클래스는 batch 단위로 처리하면 속도가 빠릅니다."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["f74f8043923742e59d84c774149bdc11","59d3838e9f7246f2a141a877c8589ebc","f6bf60bf057b4ba1a17e64e71e2fa765","b99647f13d2a47e0b336beaf6b7bc2da","e4c1934ecb614a7aaefbaa5cc1a5eed8","0373e13196324835a4204089e5a66ef9","af9a85411fa34444864a2b9842aa6cee","b7844e0ab7f646d9ab7dcd19a612cbc4","cd0d260d54e74499927c42616ae7abe3","6e0d81af95d241948e2f447ddab54f80","49b87e5fc6744ba59b384f37e46c6095","82c22284ee344f62bfc81e81f6134c1e","f3c6711aef1b49d887c5ebe6a01efe76","be8b8a49f8c144b9ac8b8272a8b87e68","735b0d426077477abab77d3a7ea71064","8cfa7d12e4514a5b8ced8ed4ab6ea448","e29d4e59948649cc838e415197d4eeef","1fddcbd78a834bfd81b41bbbec3014c2","bb3d4c7db0e24f13b86fdb140b9f9ca1","213fde19e83c4f1fb1d56b280080f975","4b1b1d98e0a0413bb827aaf2f15a953c","4e3a9e72532a4ead9e84b440106ed434","ab43e726aac9422191b60a5954ad21c2","a57753aaeaa247b69243ad6784fb7076","5a49504d01684861a8f4a16c3da44a88","5362725e40f64bac9fd6f86155ced712","382266ffdb7e4d92868a2378c06945f4","8a0fc40237f142299c6808923d32bedc","12c3915319074e40a3c1a5b9f999f4a6","73dc268bcfc44c6db0051da1e7f24ef6","1f18cd75a0c04a05acb46e26794b4513","99c57478f5274804998a386bc29c6b10","220b8417e14c4501821922d3a7b0e1e9"]},"id":"phFCL-hl2qB7","outputId":"b50ed507-9799-41f5-d3a9-b3af762ca69a","executionInfo":{"status":"ok","timestamp":1679313931806,"user_tz":-540,"elapsed":1739,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f74f8043923742e59d84c774149bdc11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)oat16/tokenizer.json:   0%|          | 0.00/2.51M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82c22284ee344f62bfc81e81f6134c1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab43e726aac9422191b60a5954ad21c2"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9z8rJ9_F2r3w","executionInfo":{"status":"ok","timestamp":1679313934267,"user_tz":-540,"elapsed":2465,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["# 테스트 데이터를 HuggingFace Dataset으로 불러옵니다.\n","data_path = '/content/drive/MyDrive/공모전/노트북으로_GPT_맛보기/data/train.csv'\n","train_df = pd.read_csv(data_path)\n","train_set = datasets.Dataset.from_pandas(train_df)\n","del train_df"]},{"cell_type":"markdown","metadata":{"id":"x8pexeK4USV0"},"source":["- [Batch mapping](https://huggingface.co/docs/datasets/about_map_batch) 기능을 활용하여 데이터 셋 전체를 미리 토큰화합니다.\n","- `{text} 한줄 요약: {summary} [EOS]` 형태로 input을 만듭니다. 문장 끝 토큰 `[EOS]`를 직접 추가합니다.\n","- input에서 생성하려는 `{summary} [EOS]` 부분만 정답 label로 남기고 나머지는 ignore_index인 -100으로 가립니다.\n","- [GPTJForCausalLM](https://huggingface.co/docs/transformers/model_doc/gptj#transformers.GPTJForCausalLM) 모델에 input_ids와 labels를 넘겨주면 logits과 loss를 계산해줍니다.\n","- loss 는 모델이 예측한 logits과 정답 label의 [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)로 계산하며 -100인 부분은 계산에서 제외됩니다."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"syGeAV_eUbf3","executionInfo":{"status":"ok","timestamp":1679313934267,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["def train_batch_preprocess(batch):\n","    prompt = \"{text} 한줄 요약:\"\n","    query_text = [prompt.format(text=text) for text in batch['text']]\n","    target_text = batch['summary']\n","    query = tokenizer(query_text)\n","    target = tokenizer(target_text)\n","\n","    input_ids = [q + t + [tokenizer.eos_token_id] for q, t in zip(query['input_ids'], target['input_ids'])]\n","    attention_mask = [q + t + [1] for q, t in zip(query['attention_mask'], target['attention_mask'])]\n","    labels = [[-100] * len(q) + t + [tokenizer.eos_token_id] for q, t in zip(query['input_ids'], target['input_ids'])]\n","\n","    # 결과로 돌려주는 값들이 추가됩니다.\n","    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["c06b22df3212471e89adf1910a610cc3","723044082c9043ae93df5280bd35f06b","08f62ac4459c44b884c83a810120af58","ac12a0f6499f4497afa5de7fd1da0e3e","9e55259642e34468a15d98c64161399a","bbaa81f10045441e9fd05983fe8af15c","c9e57677573e453e929e1ac89d1caafe","2cb51316e69742598777f6787a2bd5b7","edd2f6317aa94cf2bbabda57ead14d96","44fdb00cde5d496fb9a31e915f19e29d","6deaa2e4580c46168744d6510c361dc6"]},"id":"67NvxO6M3Drw","outputId":"8cee6dff-c8c0-481e-b02c-37fa2d9e2a73","executionInfo":{"status":"ok","timestamp":1679313975494,"user_tz":-540,"elapsed":41232,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/40400 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c06b22df3212471e89adf1910a610cc3"}},"metadata":{}}],"source":["# batch단위로 전처리를 실행합니다.\n","# 토큰화 이후에 id, text, summary는 필요없으므로 버립니다.\n","train_set = train_set.map(\n","    train_batch_preprocess,\n","    remove_columns = ['id', 'text', 'summary'],\n","    batched = True,\n","    batch_size = 1000,\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0ElL1JuZXWn","outputId":"03353f08-a4d9-4ec2-c65c-7494c8cbfee5","executionInfo":{"status":"ok","timestamp":1679313975495,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 40400\n","})\n","669\n","[10181, 13817, 465, 657, 746, 1421, 1141, 779, 3292, 6883, 7337, 10160, 60219, 633, 56154, 10716, 413, 12418, 1341, 2125, 530, 3862, 1403, 57039, 1951, 20774, 120, 63997, 327, 4169, 14180, 4800, 387, 642, 776, 779, 3292, 6883, 7337, 10160, 402, 7634, 3025, 413, 1114, 529, 374, 120, 63997, 327, 15248, 1842, 2154, 13574, 409, 5996, 379, 14565, 2383, 376, 930, 408, 2238, 708, 26442, 720, 409, 16615, 24673, 374, 120, 63997, 327, 4869, 4595, 387, 8161, 4795, 56624, 376, 7775, 395, 779, 641, 800, 118, 516, 3035, 16704, 762, 451, 393, 4595, 379, 2348, 387, 5700, 697, 10160, 378, 7634, 53554, 376, 2991, 374, 120, 63997, 327, 22462, 534, 2020, 2460, 696, 1573, 580, 534, 27589, 1997, 728, 511, 605, 387, 1431, 427, 3883, 511, 22794, 1859, 413, 52713, 385, 478, 1300, 2238, 374, 120, 63997, 327, 4579, 376, 3788, 1987, 1092, 19103, 35761, 120, 63997, 327, 23248, 2806, 10043, 4595, 387, 30001, 1575, 378, 19165, 8943, 560, 376, 513, 559, 120, 63997, 327, 1365, 5139, 1401, 10095, 409, 12695, 858, 376, 1732, 1347, 376, 796, 628, 56154, 114, 1620, 18660, 796, 628, 16930, 115, 2806, 470, 2763, 1023, 35761, 120, 63997, 327, 1197, 59684, 534, 688, 47542, 118, 17925, 1421, 2824, 533, 1180, 4169, 1320, 41604, 402, 16815, 376, 1614, 387, 3462, 395, 13744, 3266, 551, 374, 120, 63997, 327, 27771, 2124, 7370, 378, 19824, 413, 903, 374, 120, 63997, 327, 3757, 8829, 4595, 408, 33786, 387, 2066, 797, 726, 858, 10043, 15032, 35761, 120, 63997, 327, 5449, 746, 2449, 8673, 2850, 450, 22462, 534, 1573, 402, 510, 14135, 426, 374, 120, 63997, 327, 921, 858, 409, 779, 1620, 1267, 3439, 10160, 379, 23644, 34180, 1573, 533, 1210, 696, 379, 4057, 393, 29106, 387, 11881, 404, 610, 378, 19890, 374, 120, 63997, 327, 1677, 534, 1573, 378, 28323, 983, 6251, 671, 393, 9664, 523, 2381, 395, 1964, 419, 1650, 1670, 8698, 12519, 27159, 376, 35079, 52336, 7634, 393, 976, 1400, 6883, 7337, 14230, 970, 1445, 387, 6279, 374, 120, 63997, 327, 2828, 530, 1650, 983, 2460, 696, 12269, 378, 1217, 33101, 12519, 6300, 48476, 413, 2569, 7306, 783, 14230, 395, 1625, 1573, 9140, 413, 1799, 551, 374, 120, 63997, 327, 5449, 746, 4339, 409, 1341, 958, 629, 125, 530, 1303, 546, 4820, 12098, 19250, 1117, 3141, 463, 983, 5911, 2460, 23140, 9350, 463, 5937, 453, 14230, 395, 19611, 374, 120, 63997, 327, 29250, 54060, 41976, 8254, 418, 6230, 4169, 7589, 35761, 120, 63997, 327, 1210, 14604, 1013, 38282, 7914, 1717, 34676, 118, 31062, 547, 678, 696, 118, 55659, 678, 696, 376, 5575, 1138, 35761, 120, 63997, 327, 4874, 2643, 3507, 3512, 1299, 31997, 851, 47228, 378, 44760, 9769, 379, 3790, 393, 9121, 5785, 35761, 120, 63997, 327, 30220, 18765, 379, 2065, 621, 3347, 376, 3694, 702, 1821, 16846, 8010, 1915, 413, 2090, 393, 4235, 9769, 523, 1490, 702, 379, 1051, 697, 120, 63997, 327, 23248, 4536, 43359, 413, 62811, 34719, 1440, 376, 1622, 51457, 120, 63997, 327, 2200, 2747, 387, 642, 776, 5449, 746, 4339, 409, 983, 11693, 510, 3347, 1064, 2838, 567, 1398, 426, 378, 3347, 118, 2838, 413, 1688, 447, 6505, 487, 5135, 12398, 2747, 409, 2560, 374, 14230, 395, 1789, 551, 374, 120, 63997, 327, 34180, 1573, 533, 1210, 696, 1688, 383, 4169, 2747, 959, 387, 17350, 395, 6438, 4708, 35761, 120, 63997, 327, 1424, 837, 779, 6203, 426, 378, 10160, 1210, 696, 376, 779, 6203, 640, 378, 10160, 1400, 6883, 742, 1922, 4029, 379, 21505, 933, 378, 640, 374, 120, 63997, 327, 1970, 1347, 55788, 402, 6000, 2606, 378, 779, 10181, 698, 14180, 10160, 2763, 3032, 376, 2991, 374, 120, 63997, 327, 2087, 38412, 120, 63997, 327, 1400, 6883, 7337, 378, 14741, 1347, 376, 633, 1267, 678, 696, 447, 23797, 584, 499, 2217, 120, 63997, 327, 510, 2096, 2968, 132, 3292, 6883, 7337, 402, 645, 7634, 3025, 379, 2020, 2460, 696, 1677, 534, 1573, 580, 1997, 728, 511, 1006, 387, 1431, 393, 3883, 511, 5424, 1859, 413, 52713, 385, 478, 930, 2238, 877, 19824, 378, 534, 7370, 402, 903, 374, 120, 327, 1]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3292, 6883, 7337, 402, 645, 7634, 3025, 379, 2020, 2460, 696, 1677, 534, 1573, 580, 1997, 728, 511, 1006, 387, 1431, 393, 3883, 511, 5424, 1859, 413, 52713, 385, 478, 930, 2238, 877, 19824, 378, 534, 7370, 402, 903, 374, 120, 327, 1]\n"]}],"source":["# 결과를 확인합니다.\n","# (eos_token_id = 1, ignore_index = -100)\n","print(train_set)\n","print(len(train_set[0]['input_ids']))\n","print(train_set[0]['input_ids'])\n","print(train_set[0]['attention_mask'])\n","print(train_set[0]['labels'])"]},{"cell_type":"markdown","metadata":{"id":"5VSZ9VwKbI-1"},"source":["- train_set은 각 샘플마다 길이가 다릅니다.\n","- 길이가 서로 다른 샘플을 하나의 배치로 만들기 위해 collate_fn 함수를 작성합니다.\n","- GPTJ는 문장의 오른쪽 끝부터 생성하는 autoregressive 모델이므로 오른쪽 끝이 같아야합니다. left padding을 사용합니다.\n","- attention_mask는 0, labels는 -100으로 padding합니다."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"RFFO3wM0CU30","executionInfo":{"status":"ok","timestamp":1679313975495,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["def left_pad(sequence, value, max_len):\n","    return [value] * (max_len - len(sequence)) + sequence\n","\n","def collate_fn(batch, device='cuda'):\n","    length = max(len(row['input_ids']) for row in batch)\n","    input_ids = [\n","        \n","        left_pad(row['input_ids'], tokenizer.pad_token_id, length)\n","        for row in batch\n","    ]\n","    attention_mask = [\n","        left_pad(row['attention_mask'], 0, length)\n","        for row in batch\n","    ]\n","    labels = [\n","        left_pad(row['input_ids'], -100, length)\n","        for row in batch\n","    ]\n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype=torch.long , device=device),\n","        'attention_mask': torch.tensor(attention_mask, dtype=torch.long , device=device),\n","        'labels': torch.tensor(labels, dtype=torch.long , device=device),\n","    }"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"F5XKyXZvCDyx","executionInfo":{"status":"ok","timestamp":1679313975496,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["train_loader = DataLoader(\n","    train_set, batch_size=2, shuffle=True, num_workers=0,\n","    collate_fn=collate_fn,\n",")"]},{"cell_type":"markdown","metadata":{"id":"7KC4ahfScaDr"},"source":["## 모델 불러오기\n","- base model을 불러온뒤 peft model로 감싸줍니다."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["a0a184e28d5a425e9263a416a8320fb9","a171d6c153814da3b418ee01bf61deab","df7b532cf49641fb901c87e164cdb453","1ee72c6281c04426a130ef5746c7279c","7d0500c982ad44a09200894baba7e861","5a8593bfe4954c008a67b7a9646dbc55","e395edf05dff4a5cba05d62aaf04625d","f8bc77591cc847f496b1153ce8c97797","6035d67e956c4a92879ea2c66262395b","18ea6321a13a403e94a8cc9b676124b1","ab92846b07654ca195ae457a6dc7dd0c","5d3b3ee9b9924e5b9d44c6eabe579dc3","10329947c0e6475c9b7acad770ad246c","763a832872924bf3af3a008c7627d4d5","8a7cfb90403e48749c73074112afc331","391e49f65dcc4467b170e9756fbcdb23","471c29a8b124403f91426f346caab7f8","133731c5ff124d54b5f8a757d75ac259","9369f6b53dfe4a438f6fbb7be3e523bb","13077d35d90a442d91e8ffa58f565484","1f5fe63c53e9434695bcfa5e2ea92373","1461582b6a614f8b987b83b9ed7f924d"]},"id":"VKAeznLYApWA","outputId":"89e8cb11-201a-4b0d-efb2-6ef9bbc1134f","executionInfo":{"status":"ok","timestamp":1679314172264,"user_tz":-540,"elapsed":196777,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)-float16/config.json:   0%|          | 0.00/839 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0a184e28d5a425e9263a416a8320fb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/12.3G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d3b3ee9b9924e5b9d44c6eabe579dc3"}},"metadata":{}}],"source":["base_model = AutoModelForCausalLM.from_pretrained(\n","    'kakaobrain/kogpt', revision = 'KoGPT6B-ryan1.5b-float16',\n","    torch_dtype = torch.float16,\n","    device_map = 'auto',\n",")"]},{"cell_type":"markdown","metadata":{"id":"RHc92vhRdmel"},"source":["config\n","- TaskType: 앞문장에서 뒷문장을 생성하는 CAUSAL_LM입니다.\n","- r: LoRA에 사용할 rank입니다.\n","- lora_alpha: LoRA α 계수입니다. (B @ A * α/r) 형태로 들어가는 scale 계수입니다.\n","- lora_dropout: A, B 보다 앞에 추가할 Dropout 레이어의 drop 비율입니다.\n","- target_modules: LoRA를 적용할 모듈입니다. `List[str]` 형태이면 해당 키워드로 끝나는 모듈에, `str` 형태이면 정규식에 해당하는 모듈에 적용됩니다."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"TMAMA9diA9Z5","executionInfo":{"status":"ok","timestamp":1679314172264,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["peft_config = LoraConfig(\n","    task_type = TaskType.CAUSAL_LM,\n","    r=8, lora_alpha=32, lora_dropout=0.1,\n","    target_modules = ['q_proj', 'v_proj'],\n","    # target_modules = r\".*(q_proj|v_proj)\",\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SK0M7Awhlmzc","outputId":"c0303fee-2664-499b-97e5-1612a47df970","executionInfo":{"status":"ok","timestamp":1679314172265,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, base_model_name_or_path=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules=['q_proj', 'v_proj'], lora_alpha=32, lora_dropout=0.1, merge_weights=False, fan_in_fan_out=False, enable_lora=None, bias='none', modules_to_save=None)\n"]}],"source":["print(peft_config)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"40oBz7CbA9Ul","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679314184975,"user_tz":-540,"elapsed":12714,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"a9db9d8d-6800-4cae-bb68-36234c90f328"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): GPTJForCausalLM(\n","      (transformer): GPTJModel(\n","        (wte): Embedding(64512, 4096)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (h): ModuleList(\n","          (0): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (2): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (3): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (4): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (5): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (6): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (7): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (8): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (9): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (10): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (11): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (12): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (13): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (14): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (15): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (16): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (17): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (18): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (19): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (20): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (21): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (22): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (23): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (24): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (25): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (26): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (27): GPTJBlock(\n","            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPTJAttention(\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.0, inplace=False)\n","              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (v_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (q_proj): Linear(\n","                in_features=4096, out_features=4096, bias=False\n","                (lora_dropout): Dropout(p=0.1, inplace=False)\n","                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n","                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n","              )\n","              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","            )\n","            (mlp): GPTJMLP(\n","              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n","              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=64512, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":14}],"source":["peft_model = get_peft_model(base_model, peft_config)\n","peft_model.to('cuda')\n","peft_model.train()"]},{"cell_type":"markdown","metadata":{"id":"p-IXQy0MgTJu"},"source":["![LoRA adapter.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"lvkC71Cdjw94"},"source":["- LoRA peft 모델이 어떤 파라미터를 가지는지 확인해 봅시다.\n","- lora_A, lora_B 이외에는 freeze인 것이 확인 됩니다."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"P7zqnOTnFOne","outputId":"5f77de29-d8d6-43cc-b288-f50926ba84a9","executionInfo":{"status":"ok","timestamp":1679314184976,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             dtype          shape  device  requires_grad  \\\n","0    torch.float16  (64512, 4096)  cuda:0          False   \n","1    torch.float16        (4096,)  cuda:0          False   \n","2    torch.float16        (4096,)  cuda:0          False   \n","3    torch.float16   (4096, 4096)  cuda:0          False   \n","4    torch.float16   (4096, 4096)  cuda:0          False   \n","..             ...            ...     ...            ...   \n","392  torch.float16        (4096,)  cuda:0          False   \n","393  torch.float16        (4096,)  cuda:0          False   \n","394  torch.float16        (4096,)  cuda:0          False   \n","395  torch.float16  (64512, 4096)  cuda:0          False   \n","396  torch.float16       (64512,)  cuda:0          False   \n","\n","                                                  name  \n","0              base_model.model.transformer.wte.weight  \n","1         base_model.model.transformer.h.0.ln_1.weight  \n","2           base_model.model.transformer.h.0.ln_1.bias  \n","3    base_model.model.transformer.h.0.attn.k_proj.w...  \n","4    base_model.model.transformer.h.0.attn.v_proj.w...  \n","..                                                 ...  \n","392  base_model.model.transformer.h.27.mlp.fc_out.bias  \n","393           base_model.model.transformer.ln_f.weight  \n","394             base_model.model.transformer.ln_f.bias  \n","395                    base_model.model.lm_head.weight  \n","396                      base_model.model.lm_head.bias  \n","\n","[397 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-99bb40d8-424a-45cf-a9e2-8db2b478d393\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dtype</th>\n","      <th>shape</th>\n","      <th>device</th>\n","      <th>requires_grad</th>\n","      <th>name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>torch.float16</td>\n","      <td>(64512, 4096)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.wte.weight</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>torch.float16</td>\n","      <td>(4096,)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.h.0.ln_1.weight</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>torch.float16</td>\n","      <td>(4096,)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.h.0.ln_1.bias</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>torch.float16</td>\n","      <td>(4096, 4096)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.h.0.attn.k_proj.w...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>torch.float16</td>\n","      <td>(4096, 4096)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.h.0.attn.v_proj.w...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>torch.float16</td>\n","      <td>(4096,)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.h.27.mlp.fc_out.bias</td>\n","    </tr>\n","    <tr>\n","      <th>393</th>\n","      <td>torch.float16</td>\n","      <td>(4096,)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.ln_f.weight</td>\n","    </tr>\n","    <tr>\n","      <th>394</th>\n","      <td>torch.float16</td>\n","      <td>(4096,)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.transformer.ln_f.bias</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>torch.float16</td>\n","      <td>(64512, 4096)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.lm_head.weight</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>torch.float16</td>\n","      <td>(64512,)</td>\n","      <td>cuda:0</td>\n","      <td>False</td>\n","      <td>base_model.model.lm_head.bias</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>397 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99bb40d8-424a-45cf-a9e2-8db2b478d393')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-99bb40d8-424a-45cf-a9e2-8db2b478d393 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-99bb40d8-424a-45cf-a9e2-8db2b478d393');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["pd.DataFrame([\n","    (param.dtype, param.shape, param.device, param.requires_grad, name)\n","    for name, param in peft_model.named_parameters()\n","], columns=['dtype', 'shape', 'device', 'requires_grad', 'name'])"]},{"cell_type":"markdown","metadata":{"id":"NCSBeDEIn8Qy"},"source":["## 학습\n","\n","- float32, float16이 섞여있으므로 amp autocast를 활용합니다."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DMsfqYK_BQDx","executionInfo":{"status":"ok","timestamp":1679314184976,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["learning_rate = 3e-5\n","\n","optimizer = torch.optim.Adam(peft_model.parameters(), lr=learning_rate)\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"ROqqOOIOGo5H","executionInfo":{"status":"ok","timestamp":1679314184977,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["def training_step(model, batch, optimizer, scaler):\n","    optimizer.zero_grad()\n","    with torch.cuda.amp.autocast():\n","        outputs = model(\n","            input_ids = batch['input_ids'],\n","            attention_mask = batch['attention_mask'],\n","            labels = batch['labels'],\n","        )\n","        step_loss = outputs[0]\n","    scaler.scale(step_loss).backward()\n","    scaler.step(optimizer)\n","    scaler.update()\n","    return step_loss.detach()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446,"referenced_widgets":["659a612f344c4771bb0120437ab9bb85","d5dbcfc90c104224881ff9e588ba3e3a","c2d6553df54644cb9b713b677bf8eb11","a00ea1a039f14697a9b7425a203443a7","68cfe287b25f409da7b2908eaf4d5da0","c012422715a440b781d050efe131780f","e02b78ea7d37426d8edba899dc28f956","b5b69da0eaea47b08c51d33f30dd4657","0a4dfb658e484df5b58ed3db2d7f5170","b477064c6029425783cb7a8db8b43da8","a3e1b2fa4e3d429a92dd8d07dbea8007"]},"id":"11TzmgeoBQ0G","outputId":"b7554c87-583d-49b4-b3f7-46c1b878c163","executionInfo":{"status":"error","timestamp":1679314189021,"user_tz":-540,"elapsed":4053,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20200 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659a612f344c4771bb0120437ab9bb85"}},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-41e2687228ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mstep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-d21cd1aff961>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(model, batch, optimizer, scaler)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     ):\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromptLearningConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             return self.base_model(\n\u001b[0m\u001b[1;32m    531\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gptj/modeling_gptj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m    839\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gptj/modeling_gptj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 )\n\u001b[1;32m    670\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    672\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gptj/modeling_gptj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gptj/modeling_gptj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.75 GiB total capacity; 13.86 GiB already allocated; 4.81 MiB free; 13.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["NUM_EPOCHS = 1\n","\n","peft_model.train()\n","for epoch in range(NUM_EPOCHS):\n","    total_loss = 0\n","    tr_loss = torch.tensor(0.0).to('cuda')\n","    for batch_idx, batch in enumerate(tqdm(train_loader), start=1):\n","        step_loss = training_step(peft_model, batch, optimizer, scaler)\n","        tr_loss += step_loss\n","        if batch_idx % 100 == 0:\n","            print(\"{}. tr_loss: {}\".format(batch_idx, tr_loss.item()))\n","            tr_loss = torch.tensor(0.0).to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7SpZpLCYPJK","executionInfo":{"status":"aborted","timestamp":1679314189022,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["TIME_SERIAL = datetime.now(timezone(timedelta(hours=9))).strftime(\"%y%m%d-%H%M%S\")\n","PEFT_MODEL_PATH = f'/content/drive/MyDrive/공모전/노트북으로_GPT_맛보기/exp_{TIME_SERIAL}'\n","peft_model.save_pretrained(PEFT_MODEL_PATH)\n","print(PEFT_MODEL_PATH)"]},{"cell_type":"markdown","metadata":{"id":"ObuX5yaY7k9-"},"source":["## 추론\n","- base 모델을 불러오고, 저장된 PEFT 모델을 불러옵니다.\n","- 추론 과정은 참고자료2와 동일합니다. 해당 코드를 참고하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bnJiVYW7r6-","executionInfo":{"status":"aborted","timestamp":1679314189022,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["# Install Library\n","%pip install -q transformers datasets accelerate\n","%pip install -q peft"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wEMhzGBL4Xax","executionInfo":{"status":"aborted","timestamp":1679314189023,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader,Dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM \n","from peft import PeftModel\n","import os, gc\n","from datetime import datetime, timezone, timedelta\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxU7qOlg7mut","executionInfo":{"status":"aborted","timestamp":1679314189023,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["# Google Drive Mount\n","from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OgPbYoWN4qPG"},"outputs":[],"source":["# PEFT_MODEL_PATH = \"/content/drive/MyDrive/GPT_Competition/exp_??????-??????\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EGYYcRnR4gsi","executionInfo":{"status":"aborted","timestamp":1679314189023,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmR8M5Ry5bwG","executionInfo":{"status":"aborted","timestamp":1679314189023,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["base_model = AutoModelForCausalLM.from_pretrained(\n","    'kakaobrain/kogpt', revision = 'KoGPT6B-ryan1.5b-float16',\n","    torch_dtype = torch.float16,\n","    device_map = 'auto',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BATwaoph4v1j","executionInfo":{"status":"aborted","timestamp":1679314189024,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["model = PeftModel.from_pretrained(model=base_model, model_id=PEFT_MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OE4a6Io56P1g","executionInfo":{"status":"aborted","timestamp":1679314189024,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["class SummaryTestDataset(Dataset):\n","    def __init__(self, data_path, tokenizer):\n","        self._data = pd.read_csv(data_path)\n","        self.tokenizer = tokenizer\n","    \n","    def __len__(self):\n","        return len(self._data)\n","    \n","    def __getitem__(self, idx):\n","        row = self._data.iloc[idx]\n","        prompt = \"{text} 한줄 요약:\"\n","        input_text = prompt.format(text=row['text'])\n","        input_encoding = self.tokenizer(input_text)\n","\n","        result = {\n","            'input_ids': input_encoding['input_ids'],\n","            'attention_mask': input_encoding['attention_mask'],\n","        }\n","        \n","        return result\n","\n","    def _left_pad(self, sequence, value, max_len):\n","        return [value] * (max_len - len(sequence)) + sequence\n","\n","    def collate_fn(self, batch, device='cuda'):\n","        input_length = max(len(row['input_ids']) for row in batch)\n","\n","        input_ids = [\n","            self._left_pad(row['input_ids'], self.tokenizer.pad_token_id, input_length)\n","            for row in batch\n","        ]\n","        attention_mask = [\n","            self._left_pad(row['attention_mask'], 0, input_length)\n","            for row in batch\n","        ]\n","\n","        return {\n","            'input_ids': torch.tensor(input_ids, dtype=torch.long, device=device),\n","            'attention_mask': torch.tensor(attention_mask, dtype=torch.long, device=device),\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mU03Jxao6wXb","executionInfo":{"status":"aborted","timestamp":1679314189024,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["test_path = '/content/drive/MyDrive/공모전/노트북으로_GPT_맛보기/test.csv'\n","test_set = SummaryTestDataset(test_path, tokenizer)\n","test_loader = DataLoader(test_set, batch_size=2, num_workers=0, shuffle=False, collate_fn=test_set.collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gL4pw_yu6zyR","executionInfo":{"status":"aborted","timestamp":1679314189025,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["def predict():\n","    preds = []\n","    model.eval()\n","    for batch_idx, batch in enumerate(tqdm(test_loader)):\n","        with torch.no_grad():\n","            with torch.amp.autocast('cuda'):\n","                generated = model.generate(\n","                    input_ids = batch['input_ids'],\n","                    attention_mask = batch['attention_mask'],\n","\n","                    pad_token_id = tokenizer.pad_token_id,\n","                    max_new_tokens = 100,\n","                    do_sample = False,\n","                    num_beams = 1,\n","                    num_beam_groups = 1,\n","                    penalty_alpha = None,\n","                    use_cache = True,\n","\n","                    temperature = 1.0,\n","\n","                )\n","            prompted_length = batch['input_ids'].size(-1)\n","            summary_tokens = generated[:, prompted_length:]\n","            summary = tokenizer.batch_decode(summary_tokens, skip_special_tokens=True)\n","            preds.extend(summary)\n","            print(*summary, sep='\\n----------\\n',end='\\n========\\n')\n","    return preds\n","\n","preds = predict()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IaAyKWx65Z9","executionInfo":{"status":"aborted","timestamp":1679314189025,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["test_df = pd.read_csv(test_path)\n","test_df['summary'] = preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5y2uCYvKYqq","executionInfo":{"status":"aborted","timestamp":1679314189025,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"outputs":[],"source":["# 현재 시간으로 이름붙인 제출파일을 생성합니다.\n","TIME_SERIAL = datetime.now(timezone(timedelta(hours=9))).strftime(\"%y%m%d-%H%M%S\")\n","SUBMISSION_PATH = os.path.join(PEFT_MODEL_PATH, f\"{TIME_SERIAL}.csv\")\n","test_df[['id', 'summary']].to_csv(SUBMISSION_PATH, index=False)\n","print(SUBMISSION_PATH)"]},{"cell_type":"markdown","metadata":{"id":"AShefe-trrsW"},"source":["- 세션 종료하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cDdyLHAfMQRD"},"outputs":[],"source":["# 자동으로 세션을 종료하고 싶을때 사용하세요.\n","# from google.colab import runtime\n","# runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbEjgX7tqnDy"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f74f8043923742e59d84c774149bdc11":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59d3838e9f7246f2a141a877c8589ebc","IPY_MODEL_f6bf60bf057b4ba1a17e64e71e2fa765","IPY_MODEL_b99647f13d2a47e0b336beaf6b7bc2da"],"layout":"IPY_MODEL_e4c1934ecb614a7aaefbaa5cc1a5eed8"}},"59d3838e9f7246f2a141a877c8589ebc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0373e13196324835a4204089e5a66ef9","placeholder":"​","style":"IPY_MODEL_af9a85411fa34444864a2b9842aa6cee","value":"Downloading (…)okenizer_config.json: 100%"}},"f6bf60bf057b4ba1a17e64e71e2fa765":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7844e0ab7f646d9ab7dcd19a612cbc4","max":252,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd0d260d54e74499927c42616ae7abe3","value":252}},"b99647f13d2a47e0b336beaf6b7bc2da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e0d81af95d241948e2f447ddab54f80","placeholder":"​","style":"IPY_MODEL_49b87e5fc6744ba59b384f37e46c6095","value":" 252/252 [00:00&lt;00:00, 12.7kB/s]"}},"e4c1934ecb614a7aaefbaa5cc1a5eed8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0373e13196324835a4204089e5a66ef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af9a85411fa34444864a2b9842aa6cee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7844e0ab7f646d9ab7dcd19a612cbc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd0d260d54e74499927c42616ae7abe3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e0d81af95d241948e2f447ddab54f80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49b87e5fc6744ba59b384f37e46c6095":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82c22284ee344f62bfc81e81f6134c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3c6711aef1b49d887c5ebe6a01efe76","IPY_MODEL_be8b8a49f8c144b9ac8b8272a8b87e68","IPY_MODEL_735b0d426077477abab77d3a7ea71064"],"layout":"IPY_MODEL_8cfa7d12e4514a5b8ced8ed4ab6ea448"}},"f3c6711aef1b49d887c5ebe6a01efe76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e29d4e59948649cc838e415197d4eeef","placeholder":"​","style":"IPY_MODEL_1fddcbd78a834bfd81b41bbbec3014c2","value":"Downloading (…)oat16/tokenizer.json: 100%"}},"be8b8a49f8c144b9ac8b8272a8b87e68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3d4c7db0e24f13b86fdb140b9f9ca1","max":2514827,"min":0,"orientation":"horizontal","style":"IPY_MODEL_213fde19e83c4f1fb1d56b280080f975","value":2514827}},"735b0d426077477abab77d3a7ea71064":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b1b1d98e0a0413bb827aaf2f15a953c","placeholder":"​","style":"IPY_MODEL_4e3a9e72532a4ead9e84b440106ed434","value":" 2.51M/2.51M [00:00&lt;00:00, 21.5MB/s]"}},"8cfa7d12e4514a5b8ced8ed4ab6ea448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e29d4e59948649cc838e415197d4eeef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fddcbd78a834bfd81b41bbbec3014c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb3d4c7db0e24f13b86fdb140b9f9ca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"213fde19e83c4f1fb1d56b280080f975":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b1b1d98e0a0413bb827aaf2f15a953c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e3a9e72532a4ead9e84b440106ed434":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab43e726aac9422191b60a5954ad21c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a57753aaeaa247b69243ad6784fb7076","IPY_MODEL_5a49504d01684861a8f4a16c3da44a88","IPY_MODEL_5362725e40f64bac9fd6f86155ced712"],"layout":"IPY_MODEL_382266ffdb7e4d92868a2378c06945f4"}},"a57753aaeaa247b69243ad6784fb7076":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a0fc40237f142299c6808923d32bedc","placeholder":"​","style":"IPY_MODEL_12c3915319074e40a3c1a5b9f999f4a6","value":"Downloading (…)cial_tokens_map.json: 100%"}},"5a49504d01684861a8f4a16c3da44a88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73dc268bcfc44c6db0051da1e7f24ef6","max":88,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f18cd75a0c04a05acb46e26794b4513","value":88}},"5362725e40f64bac9fd6f86155ced712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99c57478f5274804998a386bc29c6b10","placeholder":"​","style":"IPY_MODEL_220b8417e14c4501821922d3a7b0e1e9","value":" 88.0/88.0 [00:00&lt;00:00, 6.84kB/s]"}},"382266ffdb7e4d92868a2378c06945f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a0fc40237f142299c6808923d32bedc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12c3915319074e40a3c1a5b9f999f4a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73dc268bcfc44c6db0051da1e7f24ef6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f18cd75a0c04a05acb46e26794b4513":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99c57478f5274804998a386bc29c6b10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"220b8417e14c4501821922d3a7b0e1e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c06b22df3212471e89adf1910a610cc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_723044082c9043ae93df5280bd35f06b","IPY_MODEL_08f62ac4459c44b884c83a810120af58","IPY_MODEL_ac12a0f6499f4497afa5de7fd1da0e3e"],"layout":"IPY_MODEL_9e55259642e34468a15d98c64161399a"}},"723044082c9043ae93df5280bd35f06b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbaa81f10045441e9fd05983fe8af15c","placeholder":"​","style":"IPY_MODEL_c9e57677573e453e929e1ac89d1caafe","value":"Map: 100%"}},"08f62ac4459c44b884c83a810120af58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cb51316e69742598777f6787a2bd5b7","max":40400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edd2f6317aa94cf2bbabda57ead14d96","value":40400}},"ac12a0f6499f4497afa5de7fd1da0e3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44fdb00cde5d496fb9a31e915f19e29d","placeholder":"​","style":"IPY_MODEL_6deaa2e4580c46168744d6510c361dc6","value":" 40400/40400 [00:40&lt;00:00, 1542.90 examples/s]"}},"9e55259642e34468a15d98c64161399a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"bbaa81f10045441e9fd05983fe8af15c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9e57677573e453e929e1ac89d1caafe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cb51316e69742598777f6787a2bd5b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edd2f6317aa94cf2bbabda57ead14d96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44fdb00cde5d496fb9a31e915f19e29d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6deaa2e4580c46168744d6510c361dc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0a184e28d5a425e9263a416a8320fb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a171d6c153814da3b418ee01bf61deab","IPY_MODEL_df7b532cf49641fb901c87e164cdb453","IPY_MODEL_1ee72c6281c04426a130ef5746c7279c"],"layout":"IPY_MODEL_7d0500c982ad44a09200894baba7e861"}},"a171d6c153814da3b418ee01bf61deab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a8593bfe4954c008a67b7a9646dbc55","placeholder":"​","style":"IPY_MODEL_e395edf05dff4a5cba05d62aaf04625d","value":"Downloading (…)-float16/config.json: 100%"}},"df7b532cf49641fb901c87e164cdb453":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8bc77591cc847f496b1153ce8c97797","max":839,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6035d67e956c4a92879ea2c66262395b","value":839}},"1ee72c6281c04426a130ef5746c7279c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18ea6321a13a403e94a8cc9b676124b1","placeholder":"​","style":"IPY_MODEL_ab92846b07654ca195ae457a6dc7dd0c","value":" 839/839 [00:00&lt;00:00, 54.4kB/s]"}},"7d0500c982ad44a09200894baba7e861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8593bfe4954c008a67b7a9646dbc55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e395edf05dff4a5cba05d62aaf04625d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8bc77591cc847f496b1153ce8c97797":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6035d67e956c4a92879ea2c66262395b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18ea6321a13a403e94a8cc9b676124b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab92846b07654ca195ae457a6dc7dd0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d3b3ee9b9924e5b9d44c6eabe579dc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10329947c0e6475c9b7acad770ad246c","IPY_MODEL_763a832872924bf3af3a008c7627d4d5","IPY_MODEL_8a7cfb90403e48749c73074112afc331"],"layout":"IPY_MODEL_391e49f65dcc4467b170e9756fbcdb23"}},"10329947c0e6475c9b7acad770ad246c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_471c29a8b124403f91426f346caab7f8","placeholder":"​","style":"IPY_MODEL_133731c5ff124d54b5f8a757d75ac259","value":"Downloading pytorch_model.bin: 100%"}},"763a832872924bf3af3a008c7627d4d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9369f6b53dfe4a438f6fbb7be3e523bb","max":12337299197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13077d35d90a442d91e8ffa58f565484","value":12337299197}},"8a7cfb90403e48749c73074112afc331":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f5fe63c53e9434695bcfa5e2ea92373","placeholder":"​","style":"IPY_MODEL_1461582b6a614f8b987b83b9ed7f924d","value":" 12.3G/12.3G [01:30&lt;00:00, 141MB/s]"}},"391e49f65dcc4467b170e9756fbcdb23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"471c29a8b124403f91426f346caab7f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"133731c5ff124d54b5f8a757d75ac259":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9369f6b53dfe4a438f6fbb7be3e523bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13077d35d90a442d91e8ffa58f565484":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f5fe63c53e9434695bcfa5e2ea92373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1461582b6a614f8b987b83b9ed7f924d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"659a612f344c4771bb0120437ab9bb85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5dbcfc90c104224881ff9e588ba3e3a","IPY_MODEL_c2d6553df54644cb9b713b677bf8eb11","IPY_MODEL_a00ea1a039f14697a9b7425a203443a7"],"layout":"IPY_MODEL_68cfe287b25f409da7b2908eaf4d5da0"}},"d5dbcfc90c104224881ff9e588ba3e3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c012422715a440b781d050efe131780f","placeholder":"​","style":"IPY_MODEL_e02b78ea7d37426d8edba899dc28f956","value":"  0%"}},"c2d6553df54644cb9b713b677bf8eb11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5b69da0eaea47b08c51d33f30dd4657","max":20200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a4dfb658e484df5b58ed3db2d7f5170","value":0}},"a00ea1a039f14697a9b7425a203443a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b477064c6029425783cb7a8db8b43da8","placeholder":"​","style":"IPY_MODEL_a3e1b2fa4e3d429a92dd8d07dbea8007","value":" 0/20200 [00:03&lt;?, ?it/s]"}},"68cfe287b25f409da7b2908eaf4d5da0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c012422715a440b781d050efe131780f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e02b78ea7d37426d8edba899dc28f956":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5b69da0eaea47b08c51d33f30dd4657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a4dfb658e484df5b58ed3db2d7f5170":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b477064c6029425783cb7a8db8b43da8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3e1b2fa4e3d429a92dd8d07dbea8007":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}